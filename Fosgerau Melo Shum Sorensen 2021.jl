#--------------------------------------------------------------------------
# Ïˆ_sim.m: Calculate Ïˆ(p) from  Fosgerau, Melo, Shum, SÃ¸rensen (2021),
#            Equation (16), p. 4, up to simulation error.
#--------------------------------------------------------------------------
#
# DESCRIPTION: Calculate a solution Ïˆ_S(p) to the problem
#           minimize{exp(W_S(v)) - v'*p subject to v in R^J}
# where W_S is the empirical approximation 
#           W_S(v):=(1/S)sum_{s=S}^{S} max_j{v_j+Îµ_{sj}}
# to the surplus W(v):=E[max_j{v_j+Îµ_j}]
# based on S independent draws from the joint distribution of
# Îµ=(Îµ_1,...,Îµ_J).
#
# INPUT ARGUMENTS:
# p:        J x 1 vector of choice probabilities (p_j>0 all j)
# Îµ:      J x S matrix of simulation draws
#
# OUTPUT ARGUMENT: 
# Ïˆ: The scalar Ïˆ_S(p)
#
# AUTHOR: The MATLAB code was written by Jesper Riis-Vestergaard SÃ¸rensen, 
# Department of Economics, University of Copenhagen, Denmark.
#   e:  jrvs@econ.ku.dk
#   w:  https://sites.google.com/site/jesperrvs
#
# DATE: 26 May 2022
#
# REFERENCE: When using this software, please cite
#   Fosgerau, Melo, Shum, SÃ¸rensen (2021) "Some remarks on CCP-based
#   estimators of dynamic models"
#   Economics Letters, Vol. 204, July 2021.
#   https://doi.org/10.1016/j.econlet.2021.109911

using Distributions, Optim, ForwardDiff, BenchmarkTools

# EXAMPLES: For each of the examples below let
J = 5;                                # number of alternatives (including outside good, if any)
p = collect(1:J) / sum(1:J);          # choice probabilities
S = 1000000;                          # number of simulation draws
Î³ = Base.MathConstants.eulergamma
ğ“‹ = zeros(J)
Îµ = rand(Gumbel(), J, S);             # J x S indep. Gumbel(0,1) draws

Wâ‚›(ğ“‹, Îµ) = mean( map(maximum, eachcol(ğ“‹ .+ Îµ)) );    # approximate surplus
fâ‚›(ğ“‹, p, Îµ) = exp(Wâ‚›(ğ“‹, Îµ)) .- ğ“‹'*p;                 # criterion (negative to turn maximization into minimization)

function Ïˆ_sim(p, Îµ; opts = Optim.Options(show_trace = false, g_tol = 1e-14))
    Ïˆâ‚€   = zeros(size(p, 1));                                        # starting value
    Ïˆ    = optimize(ğ“‹ -> fâ‚›(ğ“‹, p, Îµ), Ïˆâ‚€, NelderMead(), opts);       # optimize
    return Ïˆ
end

function Ïˆ_simAD(p, Îµ; opts = Optim.Options(show_trace = false, g_tol = 1e-14))
    Ïˆâ‚€   = zeros(size(p, 1));                                       # starting value
    âˆ‡âˆ‡fâ‚›  = TwiceDifferentiable(ğ“‹ -> fâ‚›(ğ“‹, p, Îµ), Ïˆâ‚€)
    Ïˆ    = optimize(âˆ‡âˆ‡fâ‚›, Ïˆâ‚€, NewtonTrustRegion(), opts);            # optimize
    return Ïˆ
end

N = rand(Normal(0, 1), J, 1000)

Optim.minimizer( Ïˆ_sim(p, N) )
Optim.minimizer( Ïˆ_simAD(p, N) )

# Independent Type 1 Extreme Value
    Îµ = rand(Gumbel(), J, S);             # J x S indep. Gumbel(0,1) draws
    Ïˆ = Ïˆ_simAD(p, Îµ);
    Optim.minimizer(Ïˆ)
    log.(p) .- Î³                          # do not forget the euler gamma!

# Independent N(0,1)
    Îµ = randn(J, S);                      # J x S indep. N(0,1) draws
    Ïˆ = Ïˆ_simAD(p, Îµ);
    Optim.minimizer(Ïˆ)

# Correlated Normal
    Ï = .5;
    Î£ = zeros(J, J);
    for j=1:J
        for k=1:J       
            Î£[j, k] = Ï^(abs(j-k));       # Toeplitz covariance matrix
        end
    end
    Îµ = rand(MvNormal(zeros(J), Î£), S);   # N(0_J, Î£) draws
    Ïˆ = Ïˆ_simAD(p, Îµ);
    Optim.minimizer(Ïˆ)

# for reference: 
# function âˆ‡Wâ‚›(ğ“‹, Îµ, J)                   # âˆ‡ approximate surplus
#     maxima = map(argmax, eachcol(ğ“‹ .+ Îµ));          
#     r = []
#     for i âˆˆ 1:J
#         r[i] = mean(maxima .== i)
#     end 
#     return r
# end 

# function âˆ‡fâ‚›!(G, ğ“‹, p, Îµ, J) 
#     G .= âˆ‡Wâ‚›(ğ“‹, Îµ, J) * exp(Wâ‚›(ğ“‹, Îµ)) .- p
# end 
# âˆ‡fâ‚›!(G, ğ“‹) = âˆ‡fâ‚›!(G, ğ“‹, p, Îµ, J)